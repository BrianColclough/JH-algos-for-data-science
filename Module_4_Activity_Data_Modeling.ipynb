{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgwbV1BufaWA"
      },
      "source": [
        "# <h3 align=\"center\">__Module 1 Activity__</h3>\n",
        "# <h3 align=\"center\">__Assigned at the start of Module 1__</h3>\n",
        "# <h3 align=\"center\">__Due at the end of Module 1__</h3><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddz7CFT5ffk7"
      },
      "source": [
        "# Weekly Discussion Forum Participation\n",
        "\n",
        "Each week, you are required to participate in the module’s discussion forum. The discussion forum consists of the week's Module Activity, which is released at the beginning of the module. You must complete/attempt the activity before you can post about the activity and anything that relates to the topic.\n",
        "\n",
        "## Grading of the Discussion\n",
        "\n",
        "### 1. Initial Post:\n",
        "Create your thread by **Day 5 (Saturday night at midnight, PST).**\n",
        "\n",
        "### 2. Responses:\n",
        "Respond to at least two other posts by **Day 7 (Monday night at midnight, PST).**\n",
        "\n",
        "---\n",
        "\n",
        "## Grading Criteria:\n",
        "\n",
        "Your participation will be graded as follows:\n",
        "\n",
        "### Full Credit (100 points):\n",
        "- Submit your initial post by **Day 5.**\n",
        "- Respond to at least two other posts by **Day 7.**\n",
        "\n",
        "### Half Credit (50 points):\n",
        "- If your initial post is late but you respond to two other posts.\n",
        "- If your initial post is on time but you fail to respond to at least two other posts.\n",
        "\n",
        "### No Credit (0 points):\n",
        "- If both your initial post and responses are late.\n",
        "- If you fail to submit an initial post and do not respond to any others.\n",
        "\n",
        "---\n",
        "\n",
        "## Additional Notes:\n",
        "\n",
        "- **Late Initial Posts:** Late posts will automatically receive half credit if two responses are completed on time.\n",
        "- **Substance Matters:** Responses must be thoughtful and constructive. Comments like “Great post!” or “I agree!” without further explanation will not earn credit.\n",
        "- **Balance Participation:** Aim to engage with threads that have fewer or no responses to ensure a balanced discussion.\n",
        "\n",
        "---\n",
        "\n",
        "## Avoid:\n",
        "- A number of posts within a very short time-frame, especially immediately prior to the posting deadline.\n",
        "- Posts that complement another post, and then consist of a summary of that.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCqaZs0nf1Cr"
      },
      "source": [
        "# Data Modeling Activity\n",
        "\n",
        "## Objective\n",
        "Familiarize yourself with key data modeling concepts (classification, regression, and clustering) by analyzing a dataset and discussing how different modeling approaches apply.\n",
        "\n",
        "---\n",
        "\n",
        "## Instructions\n",
        "\n",
        "### 1. Find a Dataset\n",
        "Use the `kagglehub` library to download a dataset from Kaggle. Ensure that you have set up the library with your Kaggle API key. An example of how to do this is provided below:\n",
        "\n",
        "```python\n",
        "# Install kagglehub if not already installed\n",
        "# !pip install kagglehub\n",
        "\n",
        "import kagglehub as kh\n",
        "\n",
        "# Example: Downloading a dataset\n",
        "# Replace 'dataset-owner/dataset-name' with the Kaggle dataset identifier\n",
        "kh.download('dataset-owner/dataset-name', path='./datasets')\n",
        "\n",
        "# Load the dataset\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"./datasets/your_dataset.csv\")\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "data.head()\n",
        "\n",
        "# Basic dataset summary\n",
        "data.info()\n",
        "data.describe()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Dataset Exploration\n",
        "Answer the following questions about your dataset:\n",
        "1. What types of features are present (numerical, categorical, etc.)?\n",
        "2. Are there any missing values or data quality issues?\n",
        "3. What potential problems can this dataset solve? Identify tasks for classification, regression, and clustering.\n",
        "\n",
        "Add your answers in the markdown cell below.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Tasks\n",
        "\n",
        "#### **Classification**\n",
        "- Define a classification problem in the dataset (e.g., predicting if a customer will churn).\n",
        "- Optionally, implement a simple logistic regression or decision tree model.\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Replace 'target' with your target column name\n",
        "X = data.drop(columns=[\"target\"])\n",
        "y = data[\"target\"]\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "```\n",
        "\n",
        "#### **Regression**\n",
        "- Define a regression problem in the dataset (e.g., predicting house prices).\n",
        "- Optionally, implement a simple linear regression model.\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Replace 'target' with your target column name\n",
        "X = data.drop(columns=[\"target\"])\n",
        "y = data[\"target\"]\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R-squared Score:\", r2_score(y_test, y_pred))\n",
        "```\n",
        "\n",
        "#### **Clustering**\n",
        "- Define how clustering might reveal patterns in your dataset.\n",
        "- Optionally, implement a simple k-means clustering algorithm.\n",
        "\n",
        "```python\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use only numerical features for clustering\n",
        "X = data.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Train a k-means model\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Add cluster labels to the dataset\n",
        "data[\"Cluster\"] = kmeans.labels_\n",
        "\n",
        "# Visualize the clusters (for two features, if applicable)\n",
        "plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=data[\"Cluster\"], cmap=\"viridis\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.title(\"Clustering Visualization\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Reflection and Discussion\n",
        "- How does the choice of supervised or unsupervised learning depend on the dataset and problem?\n",
        "- What challenges did you anticipate when applying each modeling technique?\n",
        "\n",
        "Add your reflections below.\n",
        "\n",
        "---\n",
        "\n",
        "## Deliverables\n",
        "1. A short description of your dataset and the problems you identified.\n",
        "2. Code and results for any implemented models (classification, regression, clustering).\n",
        "3. A brief reflection on the activity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Data from Kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset downloaded to: /Users/briancolclough/.cache/kagglehub/datasets/samanfatima7/2020-2025-google-stock-dataset/versions/1\n",
            "Loading CSV file from: /Users/briancolclough/.cache/kagglehub/datasets/samanfatima7/2020-2025-google-stock-dataset/versions/1/google_5yr_one.csv\n",
            "First 5 rows of the dataset:\n",
            "         Date              Close               High                Low  \\\n",
            "0         NaN              GOOGL              GOOGL              GOOGL   \n",
            "1  2020-06-04   70.3785171508789  71.72309429138843  69.96599205492319   \n",
            "2  2020-06-05  71.65840148925781   71.9709103787135   70.0461071028752   \n",
            "3  2020-06-08  72.05748748779297  72.10525562528537  70.88509140875318   \n",
            "4  2020-06-09  72.25852966308594  73.04079279119881  71.77484210279437   \n",
            "\n",
            "                Open    Volume  \n",
            "0              GOOGL     GOOGL  \n",
            "1   71.4971694316438  26982000  \n",
            "2  70.44520002096422  42642000  \n",
            "3    70.974667107052  33878000  \n",
            "4  71.91816171630913  33624000  \n",
            "\n",
            "Dataset description:\n",
            "              Date               Close   High    Low   Open    Volume\n",
            "count         1255                1256   1256   1256   1256      1256\n",
            "unique        1255                1238   1256   1256   1256      1250\n",
            "top     2020-06-04  105.46577453613281  GOOGL  GOOGL  GOOGL  22288000\n",
            "freq             1                   3      1      1      1         3\n",
            "**************************************************\n",
            "         Date              Close               High                Low  \\\n",
            "1  2020-06-04   70.3785171508789  71.72309429138843  69.96599205492319   \n",
            "2  2020-06-05  71.65840148925781   71.9709103787135   70.0461071028752   \n",
            "3  2020-06-08  72.05748748779297  72.10525562528537  70.88509140875318   \n",
            "4  2020-06-09  72.25852966308594  73.04079279119881  71.77484210279437   \n",
            "5  2020-06-10  72.88652801513672  73.28810385800969  72.37198974644225   \n",
            "\n",
            "                Open    Volume  \n",
            "1   71.4971694316438  26982000  \n",
            "2  70.44520002096422  42642000  \n",
            "3    70.974667107052  33878000  \n",
            "4  71.91816171630913  33624000  \n",
            "5  72.72778683921254  31762000  \n"
          ]
        }
      ],
      "source": [
        "import kagglehub as kh\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Download the dataset\n",
        "dataset_path = kh.dataset_download(\"samanfatima7/2020-2025-google-stock-dataset\")\n",
        "print(f\"Dataset downloaded to: {dataset_path}\")\n",
        "\n",
        "# The dataset contains a CSV file called 'google_5yr_one.csv'\n",
        "csv_file_path = os.path.join(dataset_path, \"google_5yr_one.csv\")\n",
        "print(f\"Loading CSV file from: {csv_file_path}\")\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "print(\"\\nDataset description:\")\n",
        "print(data.describe())\n",
        "\n",
        "\n",
        "# Remove the first row\n",
        "data = data.drop(0)\n",
        "\n",
        "print(\"*\"*50)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Dataset Exploration\n",
        "Answer the following questions about your dataset:\n",
        "1. What types of features are present (numerical, categorical, etc.)?\n",
        "2. Are there any missing values or data quality issues?\n",
        "3. What potential problems can this dataset solve? Identify tasks for classification, regression, and clustering.\n",
        "\n",
        "**1. Feature Types:**\n",
        "- **Numerical features**: Open, Close, High, Low prices (continuous financial data), and trading volume\n",
        "- Also includes data so we know the day each of these features was measured.\n",
        "\n",
        "**2. Data Quality Issues:**\n",
        "- The first row contains header-like values (\"GOOGL\") instead of numerical data which are of no use to us\n",
        "- No apparent missing values in the numerical columns after cleaning\n",
        "- Data appears to be clean and well-structured for time series analysis\n",
        "\n",
        "**3. Potential Machine Learning Problems:**\n",
        "\n",
        "**Classification Tasks:**\n",
        "- **Direction Prediction**: Predict whether the stock will go up or down the next day\n",
        "\n",
        "**Regression Tasks:**\n",
        "- **Price Prediction**: Predict future closing prices based on historical open, high, low prices and volume\n",
        "- **Next Day Open Price**: Predict tomorrow's opening price using today's trading data\n",
        "\n",
        "**Clustering Tasks:**\n",
        "- **Trading Pattern Discovery**: Group days with similar trading patterns (price movements and volume)\n",
        "- **Market Regime Identification**: Identify different market conditions (bull market, bear market, sideways) through clustering\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Classification**\n",
        "- Define a classification problem in the dataset (e.g., predicting if a customer will churn).\n",
        "- Optionally, implement a simple logistic regression or decision tree model.\n",
        "\n",
        "From here were going to predict if the stock price will go up or down the on the next day of the market."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution:\n",
            "Tomorrow_Open_Higher_Than_Today_Close\n",
            "1    661\n",
            "0    594\n",
            "Name: count, dtype: int64\n",
            "Accuracy: 0.5378486055776892\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       116\n",
            "           1       0.54      1.00      0.70       135\n",
            "\n",
            "    accuracy                           0.54       251\n",
            "   macro avg       0.27      0.50      0.35       251\n",
            "weighted avg       0.29      0.54      0.38       251\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/en-685-621/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/en-685-621/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/opt/homebrew/Caskroom/miniconda/base/envs/en-685-621/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Convert to numeric first\n",
        "numeric_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Create target variable (tomorrow's open > today's close)\n",
        "data[\"Tomorrow_Open_Higher_Than_Today_Close\"] = (data[\"Open\"].shift(-1) > data[\"Close\"]).astype(int)\n",
        "\n",
        "# Drop rows with NaN values (last row will have NaN)\n",
        "data = data.dropna()\n",
        "\n",
        "print(\"Class distribution:\")\n",
        "print(data[\"Tomorrow_Open_Higher_Than_Today_Close\"].value_counts())\n",
        "\n",
        "# Prepare features and target\n",
        "X = data.drop(columns=[\"Tomorrow_Open_Higher_Than_Today_Close\", \"Date\"])\n",
        "y = data[\"Tomorrow_Open_Higher_Than_Today_Close\"]\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train with balanced class weights\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "en-685-621",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
